쿠버네티스에서 서버의 정확한 IP 주소나 호스트 이름을 지정해 각 클라이언트 애플리케이션을 구성하려고하면 다음과 같은 이유로 동작하지 않는다.

1. 파드는 일시적이다.
2. 클라이언트는 서버인 파드의 IP 주소를 미리 알 수 없다.
    - 쿠버네티스는 노드에 파드를 스케줄링한 후 파드가 시작되기 바로 전에 파드의 IP 주소를 할당한다.
3. 클라이언트는 서비스를 지원하는 파드의 수와 IP에 상관하지 않아야 한다.
    - 파드의 개별 IP 목록을 유지할 필요가 없다.
    - 모든 파드는 단일 IP 주소로 액세스할 수 있어야 한다.

# 5.1 서비스 소개

쿠버네티스의 서비스는 동일한 서비스를 제공하는 파드 그룹에 지속적인 단일 접점을만들려고 할 때 생성하는 리소스다.

- 각 서비스는 서비스가 존재하는 동안 절대 바뀌지 않는 IP 주소와 포트가 있다.
- 클라이언트는 해당 IP와 포트로 접속한 다음 서비스를 지원하는 파드 중 하나로 연결
    - 클라이언트는 서비스를 제공하는 개별 파드의 위치를 알 필요 없어, 파드는 언제든지 클러스터 안에서 이동 할 수 잇다.

### 예제를 통한 서비스 설명

![스크린샷 2021-09-29 오전 1.17.17.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/1c431a20-8a2e-460d-be3d-fc38ed1df67b/스크린샷_2021-09-29_오전_1.17.17.png)

## 5.1.1 서비스 생성

서비스를 지원하는 파드가 한 개 혹은 그 이상일 수 있다. 서비스 연결은 서비스 뒷단의 모든 파드로 로드밸런싱된다. 그러나 정확히 어떤 파드가 서비스의 일부분인지 아닌지를 어떻게 정의할까?

- RC와 기타 파드 컨트롤러에서 레이블 셀렉터를 사용해 동일한 세트에 속하는 파드를 지정하는 방법을 그대로 사용 가능하다.

### kubectl expose로 서비스 생성

- 서비스를 생성하는 가장 쉬운 방법은 kubectl expose을 사용하는 것이다.
- expose 명령어는 레플리케이션컨트롤러에서 사용된 것과 동일한 파드 셀렉터를 사용해 서비스 리소스를 생성하고 모든 파드를 단일 IP 주소와 포트로 노출한다.

### YAML 디스크립터를 통한 서비스 생성

```yaml
apiVersion: v1
kind: Service
metadata:
	name: kubia
spec:
	ports:
	- port: 80 # 서비스가 사용할 포트
		targetPort: 8080 # 서비스가 포워드할 포트
	selector:
		app: kubia # app=kubia 레이블이 있는 모든 파드가 이 서비스에 포함된다.
```

### 새 서비스 검사하기

```yaml
$ k get svc

cluster-ip는 클러스터 내부에서만 액세스 가능.
```

### 클러스터 내에서 서비스 테스트

1. 서비스의 클러스터 ip로 요청을 보내고 응답을 로그로 남기는 파드 생성.
2. 쿠버네티스 노드로 ssh 접속후 curl
3. kubectl exec ㅕㅇ령어로 기존 파드에서 curl

### 실행 중인 컨테이너에 우너격으로 명령어 실행

kubectl esec

- 기존 파드의 컨테이너 내에서 원격으로 임의의 명령어를 실행할 수 있다.
    
    ```yaml
    $ kubectl exec <파드> -- curl -s http://...
    ```
    
    - 더블 대시(—)는 kubectl 명령줄 옵션의 끝을 의미한다.

### 서비스의 세션 어피니티 구성

클라이언트의 모든 요청을 매번 같은 파드로 리다이렉션하려면 서비스의 세션 어피니티(sessionAffinity) 속성을 기본값 None 대신 ClientIP로 설정한다.

```yaml
apiVersion: v1
kind: Service
spec:
	sessionAffinity: ClientIP
```

- 쿠버네티스는 None과 ClientIP라는 두 가지 유형의 서비스 세션 어피니티만 지원한다.

### 동일한 서비스에서 여러 개의 포트 노출

서비스는 단일 포트만 노출하지만 여러 포트를 지원할 수도 있다.

- 파드가 두 개의 포트를 수신할 경우

```yaml
apiVersion: v1
kind: Service
metadata:
	name: kubia
spec:
	ports:
	- name: http
		port: 80
		targetPort: 8080 # 포트 80은 8080에 매핑
	- name: https
		port: 443
		targetPort: 8443 # 포트 443은 8443에 매핑
	selector:
		app: kubia # app=kubia 레이블이 있는 모든 파드가 이 서비스에 포함된다.
```

- 다른 포트가 다른 파드 서브세트에 매핑되도록 하려면 서비스를 두 개 만들어야한다.

### 이름이 지정된 포트 사용

각 파드의 포트에 이름을 지정하고 서비스 스펙에서 이름을 ㅗ참조할 수도 있다.

```yaml
kind: Pod
spec:
	containers:
	- name: kubia
		ports:
		- name: http
			containerPort: 8080
		- name: https
			containerPort: 8443

##########

apiVersion: v1
kind: Service
spec:
	ports:
	- name: http
		port: 80
		targetPort: http
	...
```

 - 이렇게 할 경우 나중에 서비스 스펙을 변경하지 않고도 포트 번호를 변경할 수 있다는 큰 장점이 있다.

## 5.1.2 서비스 검색

쿠버네티스는 클라이언트 파드가 서비스의 IP와 포트를 검색할 수 있는 방법을 제공한다.

### 환경변수를 통한 서비스 검색

```yaml
$ k exec <pod> env

...
KUBERNETES_SERVICE_HOST=xx.xxx.xxx.xxx // 서비스의 클러스터 IP
KUBERNETES_SERVICE_PORT=XX // 서비스가 제공되는 포트
...
KUBIA_SERVICE_HOST=xx.xxx.xxx.xxx // 서비스의 클러스터 IP
KUBIA_SERVICE_PORT=XX // 서비스가 제공되는 포트
...
```

### DNS를 통한 서비스 검색

kube-system 네임스페이스에는 동일한 이름의 해당 서비스가 있다.

- 이 파드는 DNS 서버를 실행하며 클러스터에서 실행 중인 다른 모든 파드는 자동으로 이를 사용하도록 구성된다.(쿠버네티스는 각 컨테이너의 /etc/resolv.conf 파일을 수정해 이를 수행)
- 각 서비스 내부 DNS 서버에서 DNS 항목을 가져온다.
- 서비스 이름을 알고있는 클라이언트 파드는 환경변수 대신 FQDN으로 엑세스할 수 있다.

### FQDN을 통한 서비스 연결

### 파드의 컨테이너 내에서 셸 실행

kubectl exec -it <pod> bash

- curl <url>로 접근

### 서비스 IP에 핑을 할 수 없는 이유

서비스로 curl은 동작하지만 핑은 응답이 없다.

- 이는 서비스의 클러스터 IP가 가상 IP이므로 서비스 포트와 결합된 경우에만 의미가 있기 때문.

# 5.2 클러스터 외부에 있는 서비스 연결

서비스가 외부 IP와 포트로 연결을 전달하는 상황이 있다. 이 경우 서비스 로드밸런싱과 서비스 검색 모두 활용할 수 있다.

## 5.2.1 서비스 엔드포인트 소개

서비스는 파드에 직접 연결되지 않는다. 대신 엔드포인트 리소스가 그 사이에 있다.

```yaml
$ kubectl describe svc <서비스명>

Name:
Namespace:
Labels:
Selector: # 서비스의 파드 셀렉터는 엔드포인트 목록을 만드는 데 사용된다.
Type:
IP:
Port:
Endpoints: # 이 서비스의 엔드포인트를 나타내는 파드 IP와 포트 목록
Session Affinity:
No events.

###############

# 엔드포인트 리소스 조회
$ kubectl get endpoints kubia
NAME ENDPOINTS AGE
```

## 5.2.2 서비스 엔드포인트 수동 구성

수동으로 관리되는 엔드포인트를 사용해 서비스를 만들려면 서비스와 ㅇ네드포인트 리소스를 모두 만들어야 한다.

### 셀렉터 없이 서비스 생성

```yaml
apiVersion: v1
kind: Service
metadata:
	name: external-service # 서비스 이름은 엔드포인트 오브젝트 이름과 일치해야 한다.
spec: # 이 서비스에는 셀렉터 정의 X
	prots:
	- port: 80
```

- 80 포트로 들어오는 연결을 허용하는 external-service라는 서비스 정의
- 셀렉터가 없는 서비스를 생성하여서 엔드포인트 리소스가 자동으로 생성되지 않는다.

### 셀렉터가 없는 서비스에 관한 엔드포인트 리소스 생성

```yaml
apiVersion: v1
kind: Endpoints
metadata:
	name: external-service # 엔드포인트 오브젝트 이름은 서비스 이름과 일치해야 한다.
subsets:
	- addresses: # 서비스가 연결을 전달할 엔드포인트의 IP
		- ip: 11.11.11.11
		- ip: 22.22.22.22
		ports:
		- port: 80 # 엔드포인트 대상 포트
```

- 서비스와 엔드포인트 리소스가 모두 서버에 게시되면 파드 셀렉터가 있는 일반 서비스처럼 서비스를 사용할 수 있다.
- 서비스가 만들어진 후 만들어진 컨테이너에는 서비스의 환경변수가 포함되어 IP:PORT 쌍에 대한 모든 연결은 서비스 엔드 포인트 간에 로드밸런싱한다.

![스크린샷 2021-09-29 오후 2.53.42.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/8746a3cc-026a-4cd5-8e9b-ce9163aabc30/스크린샷_2021-09-29_오후_2.53.42.png)

## 5.2.3 외부 서비스를 위한 별칭 생성

위의 방법 대신 좀 더 간단한 방법으로 FQDN(정규화된 도메인 이름)으로 외부 서비스를 참조할 수 있다.

### ExternalName 서비스 생성

```yaml
apiVersion: v1
kind: Service
metadata:
	name: external-service 
spec:
	type: ExternalName # 서비스 유형이 ExternalName이 된다.
	externalName: someapi.somecompany.com # 실제 서비스의 정규화된 도메인 이름(FQDN)
	prots:
	- port: 80
```

- ExternalName 유형의 서비스는 ClusterIP를 얻지 못한다.

## 5.3 외부 클라이언트에 서비스 노출

외부에서 서비스를 액세스할 수 있는 몇 가지 방법이 있다.

1. **노드포트로 서비스 유형 설정**
    - 각 클러스터 노드는 노드 자체에서 포트를 열고 해당 포트로 수신된 트래픽을 서비스로 전달한다.
    - 서비스는 내부 클러스터 IP와 포트로 액세스할 수 있을 뿐만 아니라 모든 노드의 전용 포트로도 액세스할 수 있다.
2. **서비스 유형을 노드포트 유형의 확장인 로드밸런서로 설정**
    - 쿠버네티스가 실행 중인 클라욷 ㅡ인프라에서 프로비저닝된 전용 로드밸런서로 서비스에 액세스할 수 있다.
    - 클라이언트는 로드밸런서의 IP로 서비스에 액세스한다.
3. **단일 IP 주소로 여러 서비스를 노출하는 인그레스 리소스 만들기**
    - HTTP 레벨(7계층)에서 작동하므로 4계층 서비스보다 더 많은 기능을 제공할 수 있다.

## 5.3.1 노드포트 서비스 사용

서비스를 생성하고 유형을 노드포트로 설정하는 것. 노드포트 서비스를 만들면 쿠머네티스는 모든 노드에 특정 포트를 할당하고 서비스를 구성하는 파드로 들어오는 연결을 전달한다.

### 노드포트 서비스 생성

```yaml
apiVersion: v1
kind: Service
metadata:
	name: kubia-nodeport
spec: 
	type: NodePort # 서비스 유형을 노드포트로 설정
	prots:
	- port: 80 # 서비스 내부 클러스터 IP의 포트
		targetPort: 8080 # 서비스 대상 파드의 포트
		nodePort: 30123 # 각 클러스터 노드의 포트 30123으로 서비스에 액세스할 수 있다. 
		# nodePort 생략가능(생략시 쿠버네티스가 임의의 포트를 선택)
	selector:
		app: kubi
```

### 노드포트 서비스 확인

```yaml
$ k get svc kubia-nodeport
```

![스크린샷 2021-09-29 오후 3.29.57.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/071cd59e-7473-48fa-ab13-6a352298254e/스크린샷_2021-09-29_오후_3.29.57.png)

### 외부 클라이언트가 노드포트 서비스에 액세스할 수 있도록 방화벽 규칙 변경

노드포트로 서비스에 액세스하려면 해당 노드포트에 대한 외부 연결을 허용하도록 방화벽을 구성해야한다.(ex: GCP)

- p 229 참고

## 5.3.2 외부 로드밸런서로 서비스 노출

일반적으로 클라우드에서 실행되는 쿠버네티스 클러스터는 클라우드 인프라에서 로드밸런서를 자동으로 프로비저닝하는 기능을 제공한다.

- 노드포트 대신 서비스 유형을 로드밸런서로 설정하면 됨
- 로드밸런서는 공개적으로 액세스 가능한 고유한 IP 주소를 가지며 모든 연결을 서비스로 전달한다.
    - 로드밸런서의 IP 주소로 서비스 접근 가능
    - (mk는 미지원)

### 로드밸런서 서비스 생성

```yaml
apiVersion: v1
kind: Service
metadata:
	name: kubia-nodeport
spec: 
	type: LoadBalancer # 이 유형의 서비스는 쿠버네티스 클러스터를 호스팅하는 인프라에서 로드밸런서를 얻을 수 있다.
	prots:
	- port: 80 # 서비스 내부 클러스터 IP의 포트
		targetPort: 8080 # 서비스 대상 파드의 포트
	selector:
		app: kubi
```

- 여기서 특정 노드 포트를 지정할 수 있지만 지정하지 않는다.
    - 대신 쿠버네티스가 포트를 선택하게 한다.

### 로드밸런서를 통한 서비스 연결

서비스를 생성한 후 클라우드 인프라가 로드밸런서를 생성하고 IP주소를 서비스 오브젝트에 쓰는 데 시간이 걸린다. 이후 조회하면 external-ip가 나온다.

![스크린샷 2021-09-29 오후 3.48.41.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/f33725c8-af88-4b88-809a-f0578c0c9907/스크린샷_2021-09-29_오후_3.48.41.png)

## 5.3.3 외부 연결의 특성 이해

### 불필요한 네트워크 홉(네트워크에서 출발지와 목적지 사이에 위치한 경로의 한 부분)의 이해와 예방

외부 클라이언트가 노드포트로 서비스에 접속할 경우 임의로 선택된 파드가 연결을 수신한 동일한 노드에서 실행 중일 수도 있고, 그렇지 않을 수도 있다.

외부의 연결을 수신한 노드에서 실행 중인 파드로만 외부 트래픽을 전달하도록 서비스를 구성해 이 추가 홉을 방지할 수 있다.

- 서비스의 스펙 섹션의 externalTrafficPolicy 필들를 설정하면 된다.
    
    ```yaml
    spec:
    	exteranTrafficPolicy: Local
    ```
    
    - 이 설정이 있을 경우 서비스의 노드포트로 외부 연결이 열린 경우 서비스 프록시는 로컬에 실행 중인 파드를 선택한다.
    - 로컬 파드가 존재하지 않으면 연결이 중단된다.
    - 따라서 로드 밸런서는 그러한 파드가 하나 이상 있는 노드에만 연결을 전달하도록 해야 한다.
    - 각 노드별로 파드수가 다를 경우 균등 분상이되지 않을 수 있다.
        
        ![스크린샷 2021-09-29 오후 4.06.09.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/2b96dda3-0c23-41e3-86c9-263ca78d6f75/스크린샷_2021-09-29_오후_4.06.09.png)
        

### 클라이언트 IP가 보존되지 않음 인식

파드는 실제 클라이언트의 IP를 볼 수 없다.

- 위의 외부 트래픽 정책(Local External Traffic Policy)은 노드 사이에 추가 홉이 없기 때문에 SNAT 수행 X

# 5.4 인그레스 리소스로 서비스 외부 노출

### 인그레스가 필요한 이유

인그레스는 한 IP 주소로 수십 개의 서비스에 접근이 가능하도록 지원해준다.

클라이언트가 http 요청을 인그레스에 보낼 때, 요청한 호스트와 경로에 따라 요청을 전달할 서비스가 결정된다.

![스크린샷 2021-09-29 오후 4.47.20.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/da6a8540-0752-4f95-ba19-d61cfccd807b/스크린샷_2021-09-29_오후_4.47.20.png)

인그레스는 애플리케이션 계층에서 작동하며 서비스가 할 수 없는 쿠키 기반 세션 어피니티 등과 같은 기능을 제공할 수 있다.

### 인그레스 컨트롤러가 필요한 경우

인그레스 오브젝트가 제공하는 기능을 살펴보기 전에 인그레스 리소스를 작동시키려면 클러스터에 인그레서 컨트로러를 실행해야 한다.

- p.237

## 5.4.1 인그레스 리소스 생성

```yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
	name: kubia
spec:
	rules:
	- host: kubia.example.com # 인그레스는 kubia.example.com 도메인 이름을 서비스에 매핑한다.
		http:
		paths:
		- path: / # 모든 요청은 kubia-nodePort 서비스의 80포트로 전달
			backend:
				serviceName: kubia-nodeport
				servicePort: 80
```

- 클라우드 공급자의 인그레스 컨트롤러는 인그레스가 노드포트 서비스를 가리킬 것을 요구한다. 하지만 그것이 쿠버네티스 자체의 요구 사항은 아니다.

## 5.4.2 인그레스로 서비스 액세스

[http://kubia.exampl.com](http://kubia.exampl.com에) 서비스에 액세스하려면 도메인 이름이 인그레스 컨트롤러의 IP와 매핑되도록 확인해야 한다.

### 인그레스 IP 주소 얻기

```yaml
$ k get ingress
```

### 인그레스 컨트롤러가 구성된 호스트의 IP를 인그레스 엔드포인트로 지정

IP를 알고 나면 kubi.example.com을 해당 IP로 확인하도록 DNS 서버를 구성하거나, /etc/hosts에 추가할 수 있다.

### 인그레스로 파드 액세스

```yaml
$ curl [http://kubia.exampl.com](http://kubia.exampl.com에) 
```

### 인그레스 동작 방식

![스크린샷 2021-09-29 오후 5.11.25.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/4ec1b5b8-16a4-4279-a4dd-e01fa83ad0f9/스크린샷_2021-09-29_오후_5.11.25.png)

## 5.4.3 하나의 인그레스로 여러 서비스 노출

```yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
	name: kubia
spec:
	rules:
	- host: kubia.example.com # 인그레스는 kubia.example.com 도메인 이름을 서비스에 매핑한다.
		http:
		paths:
		- path: /kubia
			backend:
				serviceName: kubia
				servicePort: 80
		- path: /bar
			backend:
				serviceName: bar
				servicePort: 80
```

이 경우 URL의 경로에 따라 두 개의 다른 서비스로 전송된다. 즉, 단일 IP로 두 개의 서비스에 도달할 수 있다.

### 서로 다른 호스트로 서로 다른 서비스 매핑하기

```yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
	name: kubia
spec:
	rules:
	- host: kubia.example.com # 인그레스는 kubia.example.com 도메인 이름을 서비스에 매핑한다.
		http:
		paths:
		- path: /kubia
			backend:
				serviceName: kubia
				servicePort: 80
	- host: bar.example.com # 인그레스는 kubia.example.com 도메인 이름을 서비스에 매핑한다.
		http:
		paths:
		- path: /bar
			backend:
				serviceName: bar
				servicePort: 80
```

## 5.4.4 TLS 트래픽을 처리하도록 인그레스 구성

### 인그레스를 위한 TLS 인증서 생성

파드에서 실행 중인 애플리케이션은 TLS를 지원할 필요가 없다.

- 파드가 우베 서버를 실행하는 경우 HTTP 트래픽만 허용하고 인그레스 컨트롤러가 TLS와 관련된 모든 ㄴ것을 처리하도록 할 수 있다.
- 인증서와 개인 키를 인그레스에 첨부해야 한다.

```yaml
# 개인 키와 인증서 생성
$ openssl genrsa -out tls.key 2048
$ openssl req -new -x509 -key tls.key -out tls.cert -days 360 -subj/CN=kubia.example.com

# 두 파일을 시크릿으로 만든다
$ kubectl create secret tls tls-secret --cert=tls.cert --key=tls.key
```

- 개인 키와 인증서는 이제 tls-secret이라는 시크릿에 저장된다.
- 인그레스 오브젝트를 업데이트하면 kubia.example.com에 대한 HTTPS 요청도 수락할 수 있다.

```yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
	name: kubia
spec:
	tls:
	- hosts:
		- kubia.example.com
		secretName: tls-secret
	rules:
		- host: kubia.example.com # 인그레스는 kubia.example.com 도메인 이름을 서비스에 매핑한다.
			http:
			paths:
			- path: /kubia
				backend:
					serviceName: kubia
					servicePort: 80
	
```

# 5.5 파드가 연결을 수락할 준비가 됐을 때 신호 보내기

## 5.5.1 레디니스 프로브 소개

쿠버네티스에서는 라이브니스 프로브와 비슷하게 파드에 레디니스 프로브를 정의할 수 있다.

레디니스 프로브(readiness probe)는 주기적으로 호출되며 특정 파드가 클라이언트 요청을 수신할 수 있는지를 결정한다.

### 레디니스 프로브 유형

1. 프로세스를 실행하는 Exec 프로브는 컨테이너의 상태를 프로세스의 종료 상태 코드로 결정한다.
2. HTTP GET 프로브는 HTTP GET 요청을 컨테이너로 보내고 응답의 HTTP 상태 코드를 보고 컨테이너가 준비됐는지 여부를 결정한다.
3. TCP 소켓 프로브는 컨테이너의 지정된 포트로 TCP 연결을 연다. 소켓이 연결되면 컨테이너가 준비된 것으로 간주한다.

### 레디니스 프로브의 동작

- 컨테이너가 시작될 때 쿠버네티스는 첫 번째 레디니스 점검을 수행하기 전에 구성 가능한 시간이 경과하기를 기다리도록 구성할 수 있다.
    - 이후 주기적으로 프로브를 호출하고 레디니스 프로브의 결과에 따라 작동하낟.
- 라이브니스 프로브와 달리 레디니스 프로브는 상태 점검에 실패해도 컨테이너가 종료되거나 다시 시작되지 않는다.
    - 엔드포인트에서 제거됨
    - 레디니스 프로브는 요청을 처리할 준비가 된 파드의 컨테이너만 요청을 수신하도록 한다.

## 5.5.2 파드에 레디니스 프로브 추가

### 파드 템플릿에 레디니스 프로브 추가

```yaml
$ kubectl edit rc kubia

###

...
		spec:
			containers:
			- name: kubia
				image: luks/kubia
				readinessProbe:
					exec:
						command:
						- ls
						- /var/ready
...
```

- 레디니스 프로브는 컨테이너 내부에서 ls /var/ready 명령어를 주기적으로 수행한다.

## 5.5.3 실제 환경에서 레디니스 프로브가 수행해야 하는 기능

### 레디니스 프로브를 항상 정의하라

파드에 레디니스 프로브를 추가하지 않으면 파드가 시작하는 즉시 서비스 엔드포인트가 된다.

- 실제 파드 내 컨테이너가 실행되지 않아도 엔트포인트가 될 수 있다.

### 레디니스 프로브에 파드의 종료 코드를 포함하지 마라

쿠버네티스는 파드를 삭제하자마자 모든 서비스에서 파드를 제거한다.

# 5.6 헤드리스 서비스로 개별 파드 찾기

클라이언트가 모든 파드에 연결하려면 각 파드의 IP를 알아야 한다. 쿠버네티스는 클라이언트가 DNS 조회로 파드 IP를 찾을 수 있도록 한다.

- 일반적으로 DNS 조회를 수행하면 DNS 서버는 하나의 IP를 반환한다.
    - 쿠버네티스 서비스에 클러스터 IP가 필요하지 않으면, DNS 서버는 하나의 서비스 IP대신 파드 IP들을 반환한다.
- DNS 서버는 하나의 DNS A 레코드를 반환하는 대신 서비스에 대한 여러 개의 A 레코드를 반환한다.
    - 각 레코드는 해당 시점에 서비스를 지원하는 개별 파드의 IP를 가리킨다.

따라서 클라이언트는 간단한 DNS A 레코드 조회를 수행하고 서비스에 포함된 모든 파드의 IP를 얻을 수 있다.

## 5.6.1 헤드리스 서비스 생성

서비스 스펙의 clusterIP 필드를 None으로 설정하면 쿠버네티스는 클라이언트가 서비스의 파드에 연결할 수 있는 클러스터 IP를 할당하지 않기 때문에 서비스가 헤드리스상태가 된다.

```yaml
apiVersion: v1
kind: Service
metadata:
	name: kubia-headless
spec:
	clusterIP: None # 이 부분이 서비스를 헤드리스 서비스로 만든다.
	ports:
	- port: 80
		targetPort: 8080
	selector:
		app: kubia
```

## 5.6.2 DNS로 파드 찾기

파드가 준비되면 DNS 조회로 실제 파드 IP를 얻을 수 있는지 확인할 수 있다.

### YAML 매니페스트를 쓰지 않고 파드 실행

```yaml
$ kubectl run dnsutils --image=tutum/dnsutils --generator=run-pod/v1 --command -- sleep infinity
```

- kubectl은 어떤 종류의 레플리케이션컨트로러나 그와 유사한 장치 없이 파드를 직접 생성하도록 지시한다.

### 헤드리스 서비스를 위해 반환된 DNS A 레코드

```yaml
$ kubectl exec dnsutils nslookup kubia-headless
```

### 모든 파드 검색 - 준비되지 않은 파드도 포함

- 서비스 레이블 셀렉터에 매칭되는 모든 파드를 찾는 서비스 검색 매커니즘을 원할 때(준비되지 않은 것 포함)

```yaml
# 쿠버네티스가 파드의 레디니스 상태에 관계없이 모든 파드를 서비스에 추가되게 하려면 서비스에 다음 어노테이션을 추가해야 한다.
```

```yaml
kind: Service
metadata:
	annotations:
		service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
# 최근 publishNotReadyAddressess라는 새로운 스펙 필드를 지원한다.
```

# 5.7 서비스 문제 해결

1. 먼저 외부가 아닌 클러스터 내에서 비스의 클러스터 IP에 연결되는지 확인한다.
2. 서비스에 액세스할 수 있는지 확인하려고 서비스 IP로 핑을 할 필요 없다.
3. 레디니스 프로브를 정의했다면 성공했는지 확인하라. 그렇지 않으면 파드는 서비스에 포함되지 않는다.
4. 파드가 서비스의 일부인지 확인하려면 kubectl get endpoints를 사용해 해당 엔드포인트 오브젝트를 확인한다.
5. FQDN이나 그  일부로 서비스에 액세스하려고 하는데 작동하지 않는 경우, FQDN 대신 클러스터 IP를 사용해 액세스할 수 있는지 확인한다
6. 대상 포트가 아닌 서비스로 노출된 포트에 연결하고 있는지 확인한다.
7. 파드 IP에 직접 연결해 파드가 올바른 포트에 연결돼 있는지 확인한다.
8. 파드 IP로 애플리케이션에 액세스할 수 없는 경우 애플리케이션이 로컬호스터에만 바인딩하고 있는지 확인한다.
